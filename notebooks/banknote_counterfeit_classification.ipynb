{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Assignment: Counterfeit Banknotes - Classification"]}, {"cell_type": "markdown", "metadata": {}, "source": ["KATE expects your code to define variables with specific names that correspond to certain things we are interested in.\n", "\n", "KATE will run your notebook from top to bottom and check the latest value of those variables, so make sure you don't overwrite them.\n", "\n", "* Remember to uncomment the line assigning the variable to your answer and don't change the variable or function names.\n* Use copies of the original or previous DataFrames to make sure you do not overwrite them by mistake.\n", "\n", "You will find instructions below about how to define each variable.\n", "\n", "Once you're happy with your code, upload your notebook to KATE to check your feedback."]}, {"cell_type": "markdown", "metadata": {}, "source": ["## About the assignment\n", "\n", "This assignment is designed to go through the basic principles of handling a Supervised Learning problem. The main task is to build a classification model to accurately distinguish between genuine and counterfeit banknotes.\n", "\n", "A vital part of any supervised learning model is the validation step. In this assignment, we will go through splitting the data into training/testing sets and using *k-fold* cross-validation to tune the parameters of a Decision Tree classifier. The last step is to check the performance of our classifier using *accuracy* as a metric, construct the *ROC* curve and calculate the *AUC* metric.\n", "\n", "The implementation will be done using the `sklearn` package, which contains all the necessary tools for model training, validation, metrics etc.\n", "\n", "Please be sure to **use the variable names as specified** in this notebook.\n", "\n", "## About the data\n", "\n", "The dataset for this assignment concerns the classification of banknotes as counterfeit or not. The special printing technique that is applied to banknotes adds a unique structure to the surface of the notes. The result of this unique printing process, is that it can be used as a way to check for authenticity.\n", "\n", "The dataset examined in this assignment is extracted from images that were taken from genuine and counterfeit banknotes using an industrial camera. The next step in the creation of the data, is the application of a frequency transformation. This way it is possible to split lower and higher frequencies, determine spectral components and analyze them. This dataset uses the *Wavelet Transformation* (WT). After some data pre-processing and cleaning, the final result contains the object-specific features from the wavelet coefficients. \n", "\n", "There are 4 features in this dataset which represent the variance, skewness and kurtosis of the transformed image as well as the entropy of the image. The target variable is the class of the notes. "]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Setup\n", "\n", "First, let's load all the necessary libraries needed for this assignment"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Import numpy and pandas for data manipulation\n", "import numpy as np \n", "import pandas as pd\n", "# Import matplotlib for generating the plots\n", "import matplotlib.pyplot as plt\n", "\n", "# Import the necessary sklearn methods\n", "\n", "# Model selection methods for cross-validation\n", "from sklearn.model_selection import train_test_split, KFold, GridSearchCV\n", "# Method for feature scaling\n", "from sklearn.preprocessing import MinMaxScaler\n", "# Decision tree classifier\n", "from sklearn.tree import DecisionTreeClassifier, plot_tree\n", "# Classification metrics\n", "from sklearn.metrics import classification_report,confusion_matrix, accuracy_score\n", "from sklearn.metrics import auc,roc_curve"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Data\n", "\n", "In this assignment we will load two datasets. The first one contains the data needed for training our model (let's save it to a variable called `df`). The second one contains the data needed for evaluating our model with **KATE**. This will be our held-out test data (let's save it to a variable called `df_eval`).\n", "\n", "We will need to process `df_eval` in exactly the same way as `df`, train our model on `df` and make predictions using `df_eval`.\n", "\n", "Run the followng cell to load the data"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df = pd.read_csv('data/banknote.csv')\n", "df_eval = pd.read_csv('data/banknote_eval.csv')\n", "\n", "print(df.shape)\n", "print(df_eval.shape)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df_eval.head()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Notice that while both `df` and `df_eval` have 5 columns, the `class` column in `df_eval` is full of null values.\n", "\n", "This is because `class` is our target variable and `df_eval` is our test set. In this assignment, we will use the input features from `df_eval` to predict the `class`m and **KATE** will evaluate these predictions against the actual values. This is what's known as a held-out test set.\n", "\n", "#### Prepare input and output\n", "\n", "Prepare the input and output variables for this assginment. Store the resulting DAtaFrames to the following variables: \n", "\n", "* `X_train`: the input features of `df`\n", "* `y_train`: the output variable of `df`\n", "* `X_eval`: the input features of `df_eval`\n", "\n", "*Hint: for the `X_eval` just drop the column which contains nothing but nill values*\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Add your code below\n", "# X_train = ...\n", "# y_train = ...\n", "# X_eval = ...\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Cross-validation\n", "\n", "The next step is to use cross-validation to tune the hyperparameters of our classifier(s). For this assignment, we will use the `DecisionTreeClassifier` from `sklearn`."]}, {"cell_type": "markdown", "metadata": {}, "source": ["It is standard procedure to perform feature scaling before training a model. This way, we can bring all the features to the same range and avoid having some features being more dominant than others.\n", "\n", "For this assignment we will use Min-Max feature scaling. Basically, we will bring all the feature to a pre-defined scaled of a minimum and a maximum number. This range will be [0,1]\n", "\n", "Use the `MinMaxScaler` utility to set the training set, `X_train`, to the range of [0,1]. Save the resulting array to the same variable name `X_train`. Please ensure that this variable is a `pd.DataFrame`.\n", "\n", "*!!! It is important to use only the training set and not the entire dataset. That way we can avoid having any information of the testing set leaking to the trainig procedure*\n", "\n", "*Hint: You will need to define and fit an instance of the `MinMaxScaler`. That will be useful for the next step where we will use that instance to perform feature scaling on evaluation set as well.*"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Add your code here\n", "# scaler = ...\n", "# X_train = ...\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Use the instance of the `MinMaxScaler` that you defined in the previous step and perform scaling on the evaluation set as well. \n", "\n", "Scaling the evaluation set `X_eval`. Save the resulting array to the same variable `X_eval`. Please ensure that this variable is a `pd.DataFrame`."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Add your code here\n", "# X_eval = ...\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["The next step is to tune the hyperparameters of our selected classifier. Each method (e.g Decision Trees, SVM, Logistic Regression etc) has its own set of hyperparameters that require tuning. Fine tuning is essential in order to adress possible under- or over-fitting issues. \n", "\n", "**2. K-Fold validation**\n", "\n", "For this assignment, we will use k-fold validation on the training test, in order to pick the best set of parameters.\n", "Use the `KFold` utility to define a k-fold object. Use a 5-fold validation approach. Save it to a variable called `cv_object`. For reproducability purposes, set `shuffle = True` and `random_state = 50`. "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Add your code here\n", "# cv_object = ...\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["**3. Hyperparameter tuning**\n", "\n", "Define the values of the grid that is to be explored. To do this, create a variable called `grid_values`. This should be a dictionary where the keys are the names of the hyperparameters of the `DecisionTreeClassifier` and the values are lists that contain the desired hyperparameter values.\n", "\n", "For this assignment, create a grid for the following hyperparameters:\n", "\n", "`criterion`, `splitter`, `max_depth`, `min_samples_split`, `min_samples_leaf`, `max_leaf_nodes`, `max_features`"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Add your code here\n", "# grid_values = {...}\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Having defined the values of the grid, it is now time to use `GridSearchCV`.\n", "\n", "Define a grid search estimator and assign it to a variable called `grid_estimator`. Use `DecisionTreeClassifier` as a base estimator and set its `random_state = 10`. \n", "\n", "There is no need to define any hyperparameters, since we have already done that in the previous step (`grid_values`).\n", "\n", "Use the `cv_object` from the previous step, and `accuracy` as a scoring metric."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Add your code here\n", "# grid_estimator = ...\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Training\n", "\n", "**4. Training phase and identification of best hyperparameters**\n", "\n", "Everything is in place. We can now train our model using the training set. Use the `.fit` method of the estimator you defined in the previous step. The result will be the best estimator based on the hyperparameter values we defined."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Add your code here\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Once training is complete, uncomment and run the cell below to view the best parameters"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# grid_estimator.best_params_"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Uncomment the following code to plot the generated tree"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# plt.figure(dpi=180)\n", "# plot_tree(grid_estimator.best_estimator_)\n", "# plt.show()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Now that we have trained our model, let's see how well it performs on the training data. \n", "\n", "Create a variable `y_pred` and store the predictions of the model for the training set:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Add your code here\n", "# y_pred = ...\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Calculate the accuracy of our model on the training set using the `accuracy_score` metric. Assign the result to a variable called `accuracy`. It should be a float number, rounded to two digits (e.g 0.85)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Add your code here\n", "# accuracy = ...\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Once complete, uncomment and run the cell below to print the metric."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# print(\"Accuracy score metric on training: {}\".format(accuracy))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Validation\n", "\n", "**5. Validation step on the testing set**\n", "\n", "We can now use this model to make predictions on new, previously unseen data. It is now time to use the testing set and validate the performance of our classifier to **KATE**.\n", "\n", "Create a variable `y_eval_pred` and store the predictions of the model for the evaluation set. "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Add your code here\n", "# y_eval_pred = ...\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["At this point, we trained a model. We have also generated predictions for data without labels (`y_eval_pred`). To see how well our model has performed on the test set, you will have to submit it to **KATE**!"]}, {"cell_type": "markdown", "metadata": {}, "source": ["**6. AUC and ROC**\n", "\n", "The **AUC-ROC** is an important evaluation metric for checking any classification model's performance. It checks the performance of a classification model at various threshold settings.\n", "\n", "For this assignment, you will construct the **ROC** curve and calculate the **AUC** of our classification model. In order to achieve that, the evaluation set will be used and calculate the probability estimates of the positive class. Luckily, `sklearn` includes this functionality for Decision Trees.\n", "\n", "Create a variable `y_pred_proba` and calculate the probability estimates for the testing set."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Add your code here\n", "# y_pred_proba = ...\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["The next step is to calculate the *True Positive Rate* (TPR) and *False Positive Rate* (FPR) for various threshold values. Use the appropriate `sklearn` function and assign the results to variables named `fpr`, `tpr` and `thresholds` respictively.\n", "\n", "Furthermore, calculate the auc metric and assign its value to variable `auc_metric`. It should be a float number, rounded to 3 digits."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Add your code here\n", "# fpr, tpr, thresholds = ...\n", "# auc_metric = ...\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Uncomment the following cell and run the code to construct the ROC curve and see the AUC metric"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# plt.figure(dpi=100)\n", "# plt.title(\"Receiver operating characteristic curve\")\n", "# plt.plot(fpr,tpr, color='darkorange',label=\"ROC curve (AUC = {})\".format(auc_metric))\n", "# plt.plot([0, 1], [0, 1], color='navy',linestyle='--')\n", "# plt.ylabel(\"TPR\")\n", "# plt.xlabel(\"FPR\")\n", "# plt.legend(loc=\"lower right\")\n", "# plt.ylim([0,1])\n", "# plt.xlim([0,1])\n", "# plt.show()"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.8.5"}}, "nbformat": 4, "nbformat_minor": 4}