{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["## Healthy Blood Prediction"]}, {"cell_type": "markdown", "metadata": {}, "source": ["KATE expects your code to define variables with specific names that correspond to certain things we are interested in.\n", "\n", "KATE will run your notebook from top to bottom and check the latest value of those variables, so make sure you don't overwrite them.\n", "\n", "* Remember to uncomment the line assigning the variable to your answer and don't change the variable or function names.\n* Use copies of the original or previous DataFrames to make sure you do not overwrite them by mistake.\n", "\n", "You will find instructions below about how to define each variable.\n", "\n", "Once you're happy with your code, upload your notebook to KATE to check your feedback."]}, {"cell_type": "markdown", "metadata": {}, "source": ["This dataset was collected to help predict from a blood exam if a patient is healthy or has hepatitis C ([source](https://archive.ics.uci.edu/ml/datasets/HCV+data)). It contains the laboratory results from the blood examinations of patients and their diagnosis.\n", "\n", "While diagnostic pathways are based on expert rules (if-then-else rules), machine learning algorithms can go beyond these methods, and learn predictions rules directly from the data.\n", "\n", "Our goal in this exercise is to implement a logistic regression model for prediction and understand some of its properties. In the second part of this exercise you will implement all methods by yourself, **without using the sklearn library**.\n", "\n", "For reference, you find the `sklearn` Logistic Regression at [sklearn-logreg](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)."]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Preparing the dataset"]}, {"cell_type": "markdown", "metadata": {}, "source": ["First, load the dataset."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import pandas as pd\n", "import numpy as np\n", "import matplotlib.pyplot as plt\n", "from sklearn.linear_model import LogisticRegression"]}, {"cell_type": "code", "execution_count": null, "metadata": {"scrolled": true}, "outputs": [], "source": ["df = pd.read_csv('data/blood.csv')\n", "df.head()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["The 'Category' column indicates the health status of the patient. "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df[\"Category\"].value_counts()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["#### 1. Create target variable\n", "\n", "Create a binary variable called `healthy` that is one when the patient is a healthy (category `'0=Blood Donor'`), and zero otherwise. Inspect how many samples are healthy and how many are not, using the `value_counts()` method. \n", "\n", "Calculate the percentage of healthy patient in the dataset, and save it to the variable `perc_healthy`."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Add your code below\n", "# df[\"healthy\"] = ...\n", "# ...\n", "# perc_healthy = ...\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Once you have calculated `perc_healthy`, uncomment the cell below and print it out:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["#perc_healthy"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Note that the dataset is imbalanced, with much higher proportion of healthy samples. This imbalance makes the task harders, as there is a small number of samples from the unhealthy class to learn from."]}, {"cell_type": "markdown", "metadata": {}, "source": ["#### Inspect the columns of the model with the 'info' method. "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df.info()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["#### 2. Clean the dataset \n", "\n", "Notice in `.info()` that the Non-Null values indicate that the dataset has missing values. Print the number of missing values for each column."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}, {"cell_type": "markdown", "metadata": {}, "source": ["\n", "We must make a decision about how to correct them. Possible solutions are imputation, deletion of the problematic variables (columns) or deletion of problematic samples (rows). As there is a small number of samples with missing values (and for the sake of time), we will drop them. \n", "\n", "Create a clean dataframe by removing samples that have non-valid values, and save it to `df_clean`. \n", "\n", "Turn the categorical variable `Sex` to a valid input representation. Use a binary representation: `True` if equal to `m`, `False` otherwise.\n", "\n", "And drop any columns that won't be used in the prediction model. Use `.info()` again to check the new dataset is clean.\n", "\n", "*Hint: use the `dropna()` and `drop` methods.*"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Add your code below\n", "# df_clean = ...\n", "# df_clean[\"Sex\"] = ...\n", "# ...\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Once you have calculated `df_clean`, uncomment and run the cell below:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# df_clean.head(3)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Single variable model"]}, {"cell_type": "markdown", "metadata": {}, "source": ["We will start by analyzing a single variable column, which makes it easier to visualize the main principles of Logistic Regression. We choose the feature `AST` arbitrarily."]}, {"cell_type": "markdown", "metadata": {}, "source": ["#### 3. Visualize how the target `healthy` depends on the variable `AST` with a scatter plot.\n", "\n", "Use the `df.plot.scatter()` method and pass `ax=ax`, and `c=k` (color black).\n", "\n", "Note that the `fig` and `ax` variables can be reused in cells below to plot over this figure."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["fig,ax = plt.subplots()\n", "# Add your code below\n", "#  df.plot...\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["#### 4. Implement a function that creates and fits a logistic regression model given the input and output data. "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Add your code below\n", "# def logreg(X,Y):\n", "#    ...\n", "#    return model\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["#### 5. Fit a model named `model_AST` that predict the status `healthy` from the variable `AST`. \n", "\n", "Note: for the test on KATE to pass, use the dataframe `df` (and not `df_clean`) to define the input features `X` and the labels `y` to train your model `model_AST`."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Add your code below\n", "# X = ...\n", "# y = ...\n", "# model_AST = ...\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["#### 6. Calculate the prediction probability for each data point. \n", "\n", "Using `model_AST`, calculate the prediction probabilities for all data points, saved as `y_prob`. \n", "\n", "Plot the result using `ax.scatter()`, which will reuse the plot created above, and the command `fig` will plot the resulting figure here. Use the color blue for this new plot, using the argument `color='tab:blue'`. \n", "\n", "Note: the `tab` colors are the new standard matplotlib colors (the \"Tableau Palette\")."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Add your code below\n", "# Y_prob = ...\n", "# plt.scatter...\n", "fig"]}, {"cell_type": "markdown", "metadata": {}, "source": ["#### 7. Calculate the deterministic predictions. \n", "\n", "Calculate the deterministic predictions, deciding that it is healthy if the output probability is larger than 50%, in a variable `y_pred`. \n", "\n", "Plot the predictions for each data point, again superimposed on the results above using `ax.scatter()`. Use small red markers, using the arguments `c=tab:red` and `marker='.'`."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Add your code below\n", "# y_pred = ...\n", "# ...\n", "fig"]}, {"cell_type": "markdown", "metadata": {}, "source": ["#### 8. Notice that your model is deciding a sample is healthy if `ALS` is below a certain threhold. Calculate this threshold from the bias and weight parameters of the model. \n", " \n", "Draw the threshold as a vertical line, superimposed on the plots above using `ax.plot()`, and again in the color red. \n", "\n", "Note that this line represents a decision boundary: the model's decision is based on which side of it a sample lies.\n", "\n", "*Hint: use the `model.intercept_` and `model.coef_` attributes as bias and weight attributes respectively, and that at the decision bourdary we have $w x - b = 0$, where $w$ is the weight and $b$ the bias.*\n", "\n", "*Hint: to draw a vertical line at some value, `x`, use `ax.plot([x,x], [0,1])`.*"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Add your code below\n", "# ALS_thres = ...\n", "# plt...\n", "fig"]}, {"cell_type": "markdown", "metadata": {}, "source": ["#### 9. Calculate and plot the ROC curve for the predictions. \n", "\n", "ROC Curves summarise the trade-off between the true positive rate and false positive rate for a predictive model using different probability thresholds.\n", "\n", "ROC curves are appropriate when the observations are balanced between each class, whereas precision-recall curves are appropriate for imbalanced datasets.\n", "\n", "Use the new axis for the plot, using `ax_roc.plot()`. Limit the plot range to valid values, between zero and one."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from sklearn.metrics import roc_curve\n", "fig_roc, ax_roc = plt.subplots()\n", "# Add your code below\n", "# ROC = ...\n", "# plt...\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Analysis of multivariate logistic regression model"]}, {"cell_type": "markdown", "metadata": {}, "source": ["#### Now, we will use all the input variables."]}, {"cell_type": "markdown", "metadata": {}, "source": ["Let's start by uncommenting the cell below and inspecting the first 3 lines of our `df_clean` DataFrame."]}, {"cell_type": "code", "execution_count": null, "metadata": {"scrolled": true}, "outputs": [], "source": ["# df_clean.head(3)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["#### 10. Create a logistic regression model using all input columns from the clean data frame. \n", "\n", "#### Optimization algorithms can perform better with normalized input variables. To normalize the input features of your model (`X`), create a new variable called `X_norm` and use `X_norm` when training your model called `full_model`."]}, {"cell_type": "markdown", "metadata": {}, "source": ["*Hint:  Use the z-score transformation $$\\frac{x - \\mu}{\\sigma}$$ with the  `mean()` and `std()` methods.*"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Add your code below\n", "# X = ...\n", "# X_norm = ...\n", "# y = ...\n", "# full_model = ...\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["#### 11. Calculate the prediction probabilities. \n", "\n", "#### Plot the histograms of the prediction probabilities, separately for healthy cases and for unhealthy cases. Do you think the model is any good?\n", "\n", "Set the numbers of bins to 30 (`bins=30`), use the `step` histogram type (`histtype='step'`), and set the density mode to on (`density=True`)."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Add your code below\n", "# Y_prob2 = ...\n", "# plt.hist...\n", "# ...\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["#### The ROC curve indicate the false positive and negative error rates for different choices of decision thresholds, varying from zero to one."]}, {"cell_type": "markdown", "metadata": {}, "source": ["#### 12. Calculate the ROC for the full model.\n", "\n", "#### Superimpose the result over the ROC for the `ALS` model, reusing the `ax_roc` axis above. \n", "\n", "####  Which model has better predictions?"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Add your code below\n", "# ROC2 = ...\n", "# plt...\n", "fig_roc"]}, {"cell_type": "markdown", "metadata": {}, "source": ["#### 13. Calculate the confusion matrix for the predictions using a 50% threshold. What's the error probability for healthy cases (false negatives) and unhealthy cases (false positives)?\n", "\n", "You can review the elements of a confusion matrix in [link](https://www.nbshare.io/notebook/626706996/Learn-And-Code-Confusion-Matrix-With-Python/).\n", "\n", "#### Notice that false positives and false negatives have very different probabilities. Think about why this is the case.\n", "\n", "*Hint: Remember the imbalance in number of healthy and unhealthy samples.*"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from sklearn.metrics import confusion_matrix\n", "# Add your code below\n", "# CM = ...\n", "# false_neg = ...\n", "# false_pos = ...\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Once you have implemented the confusion matrix and the error probabilities for healthy and unhealthy cases, uncomment and run the cell below to inspect these values:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# print(CM)\n", "# print(false_neg)\n", "# print(false_pos)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["#### 14. Calculate and print the decision probability threshold that would give same error probability for false positives and false negatives. \n", "\n", "*Hint: Find where in ROC curve false negatives become larger than false positives, using the `np.where()` function. Then use the third element of the ROC output (`ROC2[2]`), which tells the probability threshold at that point of the ROC curve.*"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Add your code below\n", "# index_roc = ...\n", "# decision_thres = ...\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["When you have calculated `decision_thres`, uncomment the cell below to print it out:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# decision_thres"]}, {"cell_type": "markdown", "metadata": {}, "source": ["#### 15. Mark over the ROC curve the point corresponding to the balanced error choice above.\n", "\n", "#### Use `ax_roc.plot()` to plot over the ROC figure above. Plot a single marker by plotting the x and y values of the ROC curve in `ROC2` for the correct index. Use the plotting argument `gx` for a green X marker.\n", "\n", "#### Also, calculate the ROC point for the 50% decision threshold considered above. Mark it as a red X marker in the same figure.\n", "\n", "#### Which decision threshold is preferable? What would this preference depend on?\n", "\n", "*Hint: Think about what is worse, false positive or false negatives?*"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Add your code below\n", "# ROC_index = ...\n", "# plt.plot(...)\n", "fig_roc"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Implementing the model from scratch\n", "\n", "Most machine learning models are trained with gradient descent, updating model parameters with small changes in the direction that reduces the training loss. \n", "\n", "#### To learn in detail what goes on when we use libraries to train our model,  we will now implement the gradient descent algorithm from scratch and compare the results with the scikit-learn package model. \n", "\n", "#### We give you here the gradient and loss functions for the logistic regression model."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["sigma = lambda u: 1/(1+np.exp(-u))\n", "def gradient(w,x,y):\n", "    y_prob = sigma(x@w)\n", "    return np.dot(x.T, (y_prob - y))/len(y)\n", "\n", "def loss(w,x,y):\n", "    y_prob = sigma(x@w)\n", "    return -(y*np.log(y_prob)+(1-y)*np.log(1-y_prob)).mean()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["#### 16. Implement a function that takes the input and output of the logistic regression model and fits it using gradient descent. \n", "\n", "Use random Gaussian initialization (with unit variance), no regularization, learning rate of 2., and 200 gradient descent steps. \n", "\n", "Also, calculate the total loss at each step. Return the final weight parameters and the total loss time series."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["np.random.seed(0)\n", "# Add your code below\n", "# def fit(X,y):\n", "#    ...\n", "#    for t in ...\n", "#      ...\n", "#    return w, loss_t\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["#### 17. Fit the model to our clean and normalized inputs. \n", "\n", "#### Calculate and print the final weights, named `w`, and plot the loss over time, named `loss_t`. \n", "\n", "#### Does it learn over time? Has it nearly converged?\n", "\n", "Remember to add a constant column to the input for the bias parameter."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Add your code below\n", "# X = ...\n", "# Y = ...\n", "# w, loss_t = ...\n", "# print...\n", "# plt...\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["#### 18. Calculate and plot the probability predictions histograms for healthy and unhealthy samples. \n", "\n", "#### Use the same histogram properties as above\n", "\n", "#### Has this model learned well?\n", "\n", "*Hint: the output probability of the logistic regression model is $p(x=1) = \\sigma(w^T x-b)$*."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Add your code below\n", "# y_prob3 = ...\n", "# plt.hist...\n", "# ...\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["#### 19. Compare the coefficients learned with our model and the scikit-learn model above. \n", "\n", "#### Make a scatter plot  using `plt.scatter`, with the vector of coefficients of each of the model as arguments. \n", "\n", "#### As a reference, plot a black dashed line on the main diagonal of the plot (i.e. where x=y). \n", "\n", "*Hint: Use `plt.plot([a,a],[b,b])` for some values `a` and `b`, and `k--` as argument.* \n", "\n", "#### Also, calculate and print the correlation between these two vectors, using the method `np.corrcoef()`, named `correlation`. \n", "\n", "#### Are the two models similar? Why should they be different, similar or identical?"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Add your code below\n", "# plt.scatter...\n", "# ... \n"]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.11.4"}}, "nbformat": 4, "nbformat_minor": 4}